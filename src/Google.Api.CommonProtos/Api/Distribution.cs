/*
 * Copyright 2016 Google Inc. All Rights Reserved.
 * Use of this source code is governed by a BSD-style
 * license that can be found in the LICENSE file or at
 * https://developers.google.com/open-source/licenses/bsd
 */

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/api/distribution.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Api {

  /// <summary>Holder for reflection information generated from google/api/distribution.proto</summary>
  [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
  public static partial class DistributionReflection {

    #region Descriptor
    /// <summary>File descriptor for google/api/distribution.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static DistributionReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Ch1nb29nbGUvYXBpL2Rpc3RyaWJ1dGlvbi5wcm90bxIKZ29vZ2xlLmFwaRoc",
            "Z29vZ2xlL2FwaS9hbm5vdGF0aW9ucy5wcm90bxoZZ29vZ2xlL3Byb3RvYnVm",
            "L2FueS5wcm90bxofZ29vZ2xlL3Byb3RvYnVmL3RpbWVzdGFtcC5wcm90byKu",
            "BQoMRGlzdHJpYnV0aW9uEg0KBWNvdW50GAEgASgDEgwKBG1lYW4YAiABKAES",
            "IAoYc3VtX29mX3NxdWFyZWRfZGV2aWF0aW9uGAMgASgBEi0KBXJhbmdlGAQg",
            "ASgLMh4uZ29vZ2xlLmFwaS5EaXN0cmlidXRpb24uUmFuZ2USPgoOYnVja2V0",
            "X29wdGlvbnMYBiABKAsyJi5nb29nbGUuYXBpLkRpc3RyaWJ1dGlvbi5CdWNr",
            "ZXRPcHRpb25zEhUKDWJ1Y2tldF9jb3VudHMYByADKAMaIQoFUmFuZ2USCwoD",
            "bWluGAEgASgBEgsKA21heBgCIAEoARq1AwoNQnVja2V0T3B0aW9ucxJHCg5s",
            "aW5lYXJfYnVja2V0cxgBIAEoCzItLmdvb2dsZS5hcGkuRGlzdHJpYnV0aW9u",
            "LkJ1Y2tldE9wdGlvbnMuTGluZWFySAASUQoTZXhwb25lbnRpYWxfYnVja2V0",
            "cxgCIAEoCzIyLmdvb2dsZS5hcGkuRGlzdHJpYnV0aW9uLkJ1Y2tldE9wdGlv",
            "bnMuRXhwb25lbnRpYWxIABJLChBleHBsaWNpdF9idWNrZXRzGAMgASgLMi8u",
            "Z29vZ2xlLmFwaS5EaXN0cmlidXRpb24uQnVja2V0T3B0aW9ucy5FeHBsaWNp",
            "dEgAGkMKBkxpbmVhchIaChJudW1fZmluaXRlX2J1Y2tldHMYASABKAUSDQoF",
            "d2lkdGgYAiABKAESDgoGb2Zmc2V0GAMgASgBGk8KC0V4cG9uZW50aWFsEhoK",
            "Em51bV9maW5pdGVfYnVja2V0cxgBIAEoBRIVCg1ncm93dGhfZmFjdG9yGAIg",
            "ASgBEg0KBXNjYWxlGAMgASgBGhoKCEV4cGxpY2l0Eg4KBmJvdW5kcxgBIAMo",
            "AUIJCgdvcHRpb25zQiUKDmNvbS5nb29nbGUuYXBpQhFEaXN0cmlidXRpb25Q",
            "cm90b1ABYgZwcm90bzM="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.AnyReflection.Descriptor, global::Google.Protobuf.WellKnownTypes.TimestampReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution), global::Google.Api.Distribution.Parser, new[]{ "Count", "Mean", "SumOfSquaredDeviation", "Range", "BucketOptions", "BucketCounts" }, null, null, new pbr::GeneratedClrTypeInfo[] { new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution.Types.Range), global::Google.Api.Distribution.Types.Range.Parser, new[]{ "Min", "Max" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution.Types.BucketOptions), global::Google.Api.Distribution.Types.BucketOptions.Parser, new[]{ "LinearBuckets", "ExponentialBuckets", "ExplicitBuckets" }, new[]{ "Options" }, null, new pbr::GeneratedClrTypeInfo[] { new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution.Types.BucketOptions.Types.Linear), global::Google.Api.Distribution.Types.BucketOptions.Types.Linear.Parser, new[]{ "NumFiniteBuckets", "Width", "Offset" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential), global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential.Parser, new[]{ "NumFiniteBuckets", "GrowthFactor", "Scale" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit), global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit.Parser, new[]{ "Bounds" }, null, null, null)})})
          }));
    }
    #endregion

  }
  #region Messages
  /// <summary>
  ///  Distribution contains summary statistics for a population of values and,
  ///  optionally, a histogram representing the distribution of those values across
  ///  a specified set of histogram buckets.
  ///
  ///  The summary statistics are the count, mean, sum of the squared deviation from
  ///  the mean, the minimum, and the maximum of the set of population of values.
  ///
  ///  The histogram is based on a sequence of buckets and gives a count of values
  ///  that fall into each bucket.  The boundaries of the buckets are given either
  ///  explicitly or by specifying parameters for a method of computing them
  ///  (buckets of fixed width or buckets of exponentially increasing width).
  ///
  ///  Although it is not forbidden, it is generally a bad idea to include
  ///  non-finite values (infinities or NaNs) in the population of values, as this
  ///  will render the `mean` and `sum_of_squared_deviation` fields meaningless.
  /// </summary>
  [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
  public sealed partial class Distribution : pb::IMessage<Distribution> {
    private static readonly pb::MessageParser<Distribution> _parser = new pb::MessageParser<Distribution>(() => new Distribution());
    public static pb::MessageParser<Distribution> Parser { get { return _parser; } }

    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Api.DistributionReflection.Descriptor.MessageTypes[0]; }
    }

    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    public Distribution() {
      OnConstruction();
    }

    partial void OnConstruction();

    public Distribution(Distribution other) : this() {
      count_ = other.count_;
      mean_ = other.mean_;
      sumOfSquaredDeviation_ = other.sumOfSquaredDeviation_;
      Range = other.range_ != null ? other.Range.Clone() : null;
      BucketOptions = other.bucketOptions_ != null ? other.BucketOptions.Clone() : null;
      bucketCounts_ = other.bucketCounts_.Clone();
    }

    public Distribution Clone() {
      return new Distribution(this);
    }

    /// <summary>Field number for the "count" field.</summary>
    public const int CountFieldNumber = 1;
    private long count_;
    /// <summary>
    ///  The number of values in the population. Must be non-negative.
    /// </summary>
    public long Count {
      get { return count_; }
      set {
        count_ = value;
      }
    }

    /// <summary>Field number for the "mean" field.</summary>
    public const int MeanFieldNumber = 2;
    private double mean_;
    /// <summary>
    ///  The arithmetic mean of the values in the population. If `count` is zero
    ///  then this field must be zero.
    /// </summary>
    public double Mean {
      get { return mean_; }
      set {
        mean_ = value;
      }
    }

    /// <summary>Field number for the "sum_of_squared_deviation" field.</summary>
    public const int SumOfSquaredDeviationFieldNumber = 3;
    private double sumOfSquaredDeviation_;
    /// <summary>
    ///  The sum of squared deviations from the mean of the values in the
    ///  population.  For values x_i this is:
    ///
    ///      Sum[i=1..n]((x_i - mean)^2)
    ///
    ///  Knuth, "The Art of Computer Programming", Vol. 2, page 323, 3rd edition
    ///  describes Welford's method for accumulating this sum in one pass.
    ///
    ///  If `count` is zero then this field must be zero.
    /// </summary>
    public double SumOfSquaredDeviation {
      get { return sumOfSquaredDeviation_; }
      set {
        sumOfSquaredDeviation_ = value;
      }
    }

    /// <summary>Field number for the "range" field.</summary>
    public const int RangeFieldNumber = 4;
    private global::Google.Api.Distribution.Types.Range range_;
    /// <summary>
    ///  If specified, contains the range of the population values. The field
    ///  must not be present if the `count` is zero.
    /// </summary>
    public global::Google.Api.Distribution.Types.Range Range {
      get { return range_; }
      set {
        range_ = value;
      }
    }

    /// <summary>Field number for the "bucket_options" field.</summary>
    public const int BucketOptionsFieldNumber = 6;
    private global::Google.Api.Distribution.Types.BucketOptions bucketOptions_;
    /// <summary>
    ///  Defines the histogram bucket boundaries.
    /// </summary>
    public global::Google.Api.Distribution.Types.BucketOptions BucketOptions {
      get { return bucketOptions_; }
      set {
        bucketOptions_ = value;
      }
    }

    /// <summary>Field number for the "bucket_counts" field.</summary>
    public const int BucketCountsFieldNumber = 7;
    private static readonly pb::FieldCodec<long> _repeated_bucketCounts_codec
        = pb::FieldCodec.ForInt64(58);
    private readonly pbc::RepeatedField<long> bucketCounts_ = new pbc::RepeatedField<long>();
    /// <summary>
    ///  If `bucket_options` is given, then the sum of the values in `bucket_counts`
    ///  must equal the value in `count`.  If `bucket_options` is not given, no
    ///  `bucket_counts` fields may be given.
    ///
    ///  Bucket counts are given in order under the numbering scheme described
    ///  above (the underflow bucket has number 0; the finite buckets, if any,
    ///  have numbers 1 through N-2; the overflow bucket has number N-1).
    ///
    ///  The size of `bucket_counts` must be no greater than N as defined in
    ///  `bucket_options`.
    ///
    ///  Any suffix of trailing zero bucket_count fields may be omitted.
    /// </summary>
    public pbc::RepeatedField<long> BucketCounts {
      get { return bucketCounts_; }
    }

    public override bool Equals(object other) {
      return Equals(other as Distribution);
    }

    public bool Equals(Distribution other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Count != other.Count) return false;
      if (Mean != other.Mean) return false;
      if (SumOfSquaredDeviation != other.SumOfSquaredDeviation) return false;
      if (!object.Equals(Range, other.Range)) return false;
      if (!object.Equals(BucketOptions, other.BucketOptions)) return false;
      if(!bucketCounts_.Equals(other.bucketCounts_)) return false;
      return true;
    }

    public override int GetHashCode() {
      int hash = 1;
      if (Count != 0L) hash ^= Count.GetHashCode();
      if (Mean != 0D) hash ^= Mean.GetHashCode();
      if (SumOfSquaredDeviation != 0D) hash ^= SumOfSquaredDeviation.GetHashCode();
      if (range_ != null) hash ^= Range.GetHashCode();
      if (bucketOptions_ != null) hash ^= BucketOptions.GetHashCode();
      hash ^= bucketCounts_.GetHashCode();
      return hash;
    }

    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    public void WriteTo(pb::CodedOutputStream output) {
      if (Count != 0L) {
        output.WriteRawTag(8);
        output.WriteInt64(Count);
      }
      if (Mean != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Mean);
      }
      if (SumOfSquaredDeviation != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(SumOfSquaredDeviation);
      }
      if (range_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Range);
      }
      if (bucketOptions_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(BucketOptions);
      }
      bucketCounts_.WriteTo(output, _repeated_bucketCounts_codec);
    }

    public int CalculateSize() {
      int size = 0;
      if (Count != 0L) {
        size += 1 + pb::CodedOutputStream.ComputeInt64Size(Count);
      }
      if (Mean != 0D) {
        size += 1 + 8;
      }
      if (SumOfSquaredDeviation != 0D) {
        size += 1 + 8;
      }
      if (range_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Range);
      }
      if (bucketOptions_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(BucketOptions);
      }
      size += bucketCounts_.CalculateSize(_repeated_bucketCounts_codec);
      return size;
    }

    public void MergeFrom(Distribution other) {
      if (other == null) {
        return;
      }
      if (other.Count != 0L) {
        Count = other.Count;
      }
      if (other.Mean != 0D) {
        Mean = other.Mean;
      }
      if (other.SumOfSquaredDeviation != 0D) {
        SumOfSquaredDeviation = other.SumOfSquaredDeviation;
      }
      if (other.range_ != null) {
        if (range_ == null) {
          range_ = new global::Google.Api.Distribution.Types.Range();
        }
        Range.MergeFrom(other.Range);
      }
      if (other.bucketOptions_ != null) {
        if (bucketOptions_ == null) {
          bucketOptions_ = new global::Google.Api.Distribution.Types.BucketOptions();
        }
        BucketOptions.MergeFrom(other.BucketOptions);
      }
      bucketCounts_.Add(other.bucketCounts_);
    }

    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            Count = input.ReadInt64();
            break;
          }
          case 17: {
            Mean = input.ReadDouble();
            break;
          }
          case 25: {
            SumOfSquaredDeviation = input.ReadDouble();
            break;
          }
          case 34: {
            if (range_ == null) {
              range_ = new global::Google.Api.Distribution.Types.Range();
            }
            input.ReadMessage(range_);
            break;
          }
          case 50: {
            if (bucketOptions_ == null) {
              bucketOptions_ = new global::Google.Api.Distribution.Types.BucketOptions();
            }
            input.ReadMessage(bucketOptions_);
            break;
          }
          case 58:
          case 56: {
            bucketCounts_.AddEntriesFrom(input, _repeated_bucketCounts_codec);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the Distribution message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
    public static partial class Types {
      /// <summary>
      ///  The range of the population values.
      /// </summary>
      [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
      public sealed partial class Range : pb::IMessage<Range> {
        private static readonly pb::MessageParser<Range> _parser = new pb::MessageParser<Range>(() => new Range());
        public static pb::MessageParser<Range> Parser { get { return _parser; } }

        public static pbr::MessageDescriptor Descriptor {
          get { return global::Google.Api.Distribution.Descriptor.NestedTypes[0]; }
        }

        pbr::MessageDescriptor pb::IMessage.Descriptor {
          get { return Descriptor; }
        }

        public Range() {
          OnConstruction();
        }

        partial void OnConstruction();

        public Range(Range other) : this() {
          min_ = other.min_;
          max_ = other.max_;
        }

        public Range Clone() {
          return new Range(this);
        }

        /// <summary>Field number for the "min" field.</summary>
        public const int MinFieldNumber = 1;
        private double min_;
        /// <summary>
        ///  The minimum of the population values.
        /// </summary>
        public double Min {
          get { return min_; }
          set {
            min_ = value;
          }
        }

        /// <summary>Field number for the "max" field.</summary>
        public const int MaxFieldNumber = 2;
        private double max_;
        /// <summary>
        ///  The maximum of the population values.
        /// </summary>
        public double Max {
          get { return max_; }
          set {
            max_ = value;
          }
        }

        public override bool Equals(object other) {
          return Equals(other as Range);
        }

        public bool Equals(Range other) {
          if (ReferenceEquals(other, null)) {
            return false;
          }
          if (ReferenceEquals(other, this)) {
            return true;
          }
          if (Min != other.Min) return false;
          if (Max != other.Max) return false;
          return true;
        }

        public override int GetHashCode() {
          int hash = 1;
          if (Min != 0D) hash ^= Min.GetHashCode();
          if (Max != 0D) hash ^= Max.GetHashCode();
          return hash;
        }

        public override string ToString() {
          return pb::JsonFormatter.ToDiagnosticString(this);
        }

        public void WriteTo(pb::CodedOutputStream output) {
          if (Min != 0D) {
            output.WriteRawTag(9);
            output.WriteDouble(Min);
          }
          if (Max != 0D) {
            output.WriteRawTag(17);
            output.WriteDouble(Max);
          }
        }

        public int CalculateSize() {
          int size = 0;
          if (Min != 0D) {
            size += 1 + 8;
          }
          if (Max != 0D) {
            size += 1 + 8;
          }
          return size;
        }

        public void MergeFrom(Range other) {
          if (other == null) {
            return;
          }
          if (other.Min != 0D) {
            Min = other.Min;
          }
          if (other.Max != 0D) {
            Max = other.Max;
          }
        }

        public void MergeFrom(pb::CodedInputStream input) {
          uint tag;
          while ((tag = input.ReadTag()) != 0) {
            switch(tag) {
              default:
                input.SkipLastField();
                break;
              case 9: {
                Min = input.ReadDouble();
                break;
              }
              case 17: {
                Max = input.ReadDouble();
                break;
              }
            }
          }
        }

      }

      /// <summary>
      ///  A Distribution may optionally contain a histogram of the values in the
      ///  population.  The histogram is given in `bucket_counts` as counts of values
      ///  that fall into one of a sequence of non-overlapping buckets.  The sequence
      ///  of buckets is described by `bucket_options`.
      ///
      ///  A bucket specifies an inclusive lower bound and exclusive upper bound for
      ///  the values that are counted for that bucket.  The upper bound of a bucket
      ///  is strictly greater than the lower bound.
      ///
      ///  The sequence of N buckets for a Distribution consists of an underflow
      ///  bucket (number 0), zero or more finite buckets (number 1 through N - 2) and
      ///  an overflow bucket (number N - 1).  The buckets are contiguous:  the lower
      ///  bound of bucket i (i > 0) is the same as the upper bound of bucket i - 1.
      ///  The buckets span the whole range of finite values: lower bound of the
      ///  underflow bucket is -infinity and the upper bound of the overflow bucket is
      ///  +infinity.  The finite buckets are so-called because both bounds are
      ///  finite.
      ///
      ///  `BucketOptions` describes bucket boundaries in one of three ways.  Two
      ///  describe the boundaries by giving parameters for a formula to generate
      ///  boundaries and one gives the bucket boundaries explicitly.
      ///
      ///  If `bucket_boundaries` is not given, then no `bucket_counts` may be given.
      /// </summary>
      [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
      public sealed partial class BucketOptions : pb::IMessage<BucketOptions> {
        private static readonly pb::MessageParser<BucketOptions> _parser = new pb::MessageParser<BucketOptions>(() => new BucketOptions());
        public static pb::MessageParser<BucketOptions> Parser { get { return _parser; } }

        public static pbr::MessageDescriptor Descriptor {
          get { return global::Google.Api.Distribution.Descriptor.NestedTypes[1]; }
        }

        pbr::MessageDescriptor pb::IMessage.Descriptor {
          get { return Descriptor; }
        }

        public BucketOptions() {
          OnConstruction();
        }

        partial void OnConstruction();

        public BucketOptions(BucketOptions other) : this() {
          switch (other.OptionsCase) {
            case OptionsOneofCase.LinearBuckets:
              LinearBuckets = other.LinearBuckets.Clone();
              break;
            case OptionsOneofCase.ExponentialBuckets:
              ExponentialBuckets = other.ExponentialBuckets.Clone();
              break;
            case OptionsOneofCase.ExplicitBuckets:
              ExplicitBuckets = other.ExplicitBuckets.Clone();
              break;
          }

        }

        public BucketOptions Clone() {
          return new BucketOptions(this);
        }

        /// <summary>Field number for the "linear_buckets" field.</summary>
        public const int LinearBucketsFieldNumber = 1;
        /// <summary>
        ///  The linear bucket.
        /// </summary>
        public global::Google.Api.Distribution.Types.BucketOptions.Types.Linear LinearBuckets {
          get { return optionsCase_ == OptionsOneofCase.LinearBuckets ? (global::Google.Api.Distribution.Types.BucketOptions.Types.Linear) options_ : null; }
          set {
            options_ = value;
            optionsCase_ = value == null ? OptionsOneofCase.None : OptionsOneofCase.LinearBuckets;
          }
        }

        /// <summary>Field number for the "exponential_buckets" field.</summary>
        public const int ExponentialBucketsFieldNumber = 2;
        /// <summary>
        ///  The exponential buckets.
        /// </summary>
        public global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential ExponentialBuckets {
          get { return optionsCase_ == OptionsOneofCase.ExponentialBuckets ? (global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential) options_ : null; }
          set {
            options_ = value;
            optionsCase_ = value == null ? OptionsOneofCase.None : OptionsOneofCase.ExponentialBuckets;
          }
        }

        /// <summary>Field number for the "explicit_buckets" field.</summary>
        public const int ExplicitBucketsFieldNumber = 3;
        /// <summary>
        ///  The explicit buckets.
        /// </summary>
        public global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit ExplicitBuckets {
          get { return optionsCase_ == OptionsOneofCase.ExplicitBuckets ? (global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit) options_ : null; }
          set {
            options_ = value;
            optionsCase_ = value == null ? OptionsOneofCase.None : OptionsOneofCase.ExplicitBuckets;
          }
        }

        private object options_;
        /// <summary>Enum of possible cases for the "options" oneof.</summary>
        public enum OptionsOneofCase {
          None = 0,
          LinearBuckets = 1,
          ExponentialBuckets = 2,
          ExplicitBuckets = 3,
        }
        private OptionsOneofCase optionsCase_ = OptionsOneofCase.None;
        public OptionsOneofCase OptionsCase {
          get { return optionsCase_; }
        }

        public void ClearOptions() {
          optionsCase_ = OptionsOneofCase.None;
          options_ = null;
        }

        public override bool Equals(object other) {
          return Equals(other as BucketOptions);
        }

        public bool Equals(BucketOptions other) {
          if (ReferenceEquals(other, null)) {
            return false;
          }
          if (ReferenceEquals(other, this)) {
            return true;
          }
          if (!object.Equals(LinearBuckets, other.LinearBuckets)) return false;
          if (!object.Equals(ExponentialBuckets, other.ExponentialBuckets)) return false;
          if (!object.Equals(ExplicitBuckets, other.ExplicitBuckets)) return false;
          if (OptionsCase != other.OptionsCase) return false;
          return true;
        }

        public override int GetHashCode() {
          int hash = 1;
          if (optionsCase_ == OptionsOneofCase.LinearBuckets) hash ^= LinearBuckets.GetHashCode();
          if (optionsCase_ == OptionsOneofCase.ExponentialBuckets) hash ^= ExponentialBuckets.GetHashCode();
          if (optionsCase_ == OptionsOneofCase.ExplicitBuckets) hash ^= ExplicitBuckets.GetHashCode();
          hash ^= (int) optionsCase_;
          return hash;
        }

        public override string ToString() {
          return pb::JsonFormatter.ToDiagnosticString(this);
        }

        public void WriteTo(pb::CodedOutputStream output) {
          if (optionsCase_ == OptionsOneofCase.LinearBuckets) {
            output.WriteRawTag(10);
            output.WriteMessage(LinearBuckets);
          }
          if (optionsCase_ == OptionsOneofCase.ExponentialBuckets) {
            output.WriteRawTag(18);
            output.WriteMessage(ExponentialBuckets);
          }
          if (optionsCase_ == OptionsOneofCase.ExplicitBuckets) {
            output.WriteRawTag(26);
            output.WriteMessage(ExplicitBuckets);
          }
        }

        public int CalculateSize() {
          int size = 0;
          if (optionsCase_ == OptionsOneofCase.LinearBuckets) {
            size += 1 + pb::CodedOutputStream.ComputeMessageSize(LinearBuckets);
          }
          if (optionsCase_ == OptionsOneofCase.ExponentialBuckets) {
            size += 1 + pb::CodedOutputStream.ComputeMessageSize(ExponentialBuckets);
          }
          if (optionsCase_ == OptionsOneofCase.ExplicitBuckets) {
            size += 1 + pb::CodedOutputStream.ComputeMessageSize(ExplicitBuckets);
          }
          return size;
        }

        public void MergeFrom(BucketOptions other) {
          if (other == null) {
            return;
          }
          switch (other.OptionsCase) {
            case OptionsOneofCase.LinearBuckets:
              LinearBuckets = other.LinearBuckets;
              break;
            case OptionsOneofCase.ExponentialBuckets:
              ExponentialBuckets = other.ExponentialBuckets;
              break;
            case OptionsOneofCase.ExplicitBuckets:
              ExplicitBuckets = other.ExplicitBuckets;
              break;
          }

        }

        public void MergeFrom(pb::CodedInputStream input) {
          uint tag;
          while ((tag = input.ReadTag()) != 0) {
            switch(tag) {
              default:
                input.SkipLastField();
                break;
              case 10: {
                global::Google.Api.Distribution.Types.BucketOptions.Types.Linear subBuilder = new global::Google.Api.Distribution.Types.BucketOptions.Types.Linear();
                if (optionsCase_ == OptionsOneofCase.LinearBuckets) {
                  subBuilder.MergeFrom(LinearBuckets);
                }
                input.ReadMessage(subBuilder);
                LinearBuckets = subBuilder;
                break;
              }
              case 18: {
                global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential subBuilder = new global::Google.Api.Distribution.Types.BucketOptions.Types.Exponential();
                if (optionsCase_ == OptionsOneofCase.ExponentialBuckets) {
                  subBuilder.MergeFrom(ExponentialBuckets);
                }
                input.ReadMessage(subBuilder);
                ExponentialBuckets = subBuilder;
                break;
              }
              case 26: {
                global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit subBuilder = new global::Google.Api.Distribution.Types.BucketOptions.Types.Explicit();
                if (optionsCase_ == OptionsOneofCase.ExplicitBuckets) {
                  subBuilder.MergeFrom(ExplicitBuckets);
                }
                input.ReadMessage(subBuilder);
                ExplicitBuckets = subBuilder;
                break;
              }
            }
          }
        }

        #region Nested types
        /// <summary>Container for nested types declared in the BucketOptions message type.</summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
        public static partial class Types {
          /// <summary>
          ///  Specify a sequence of buckets that all have the same width (except
          ///  overflow and underflow).  Each bucket represents a constant absolute
          ///  uncertainty on the specific value in the bucket.
          ///
          ///  Defines `num_finite_buckets + 2` (= N) buckets with these boundaries for
          ///  bucket `i`:
          ///
          ///     Upper bound (0 &lt;= i &lt; N-1):     offset + (width * i).
          ///     Lower bound (1 &lt;= i &lt; N):       offset + (width * (i - 1)).
          /// </summary>
          [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
          public sealed partial class Linear : pb::IMessage<Linear> {
            private static readonly pb::MessageParser<Linear> _parser = new pb::MessageParser<Linear>(() => new Linear());
            public static pb::MessageParser<Linear> Parser { get { return _parser; } }

            public static pbr::MessageDescriptor Descriptor {
              get { return global::Google.Api.Distribution.Types.BucketOptions.Descriptor.NestedTypes[0]; }
            }

            pbr::MessageDescriptor pb::IMessage.Descriptor {
              get { return Descriptor; }
            }

            public Linear() {
              OnConstruction();
            }

            partial void OnConstruction();

            public Linear(Linear other) : this() {
              numFiniteBuckets_ = other.numFiniteBuckets_;
              width_ = other.width_;
              offset_ = other.offset_;
            }

            public Linear Clone() {
              return new Linear(this);
            }

            /// <summary>Field number for the "num_finite_buckets" field.</summary>
            public const int NumFiniteBucketsFieldNumber = 1;
            private int numFiniteBuckets_;
            /// <summary>
            ///  Must be greater than 0.
            /// </summary>
            public int NumFiniteBuckets {
              get { return numFiniteBuckets_; }
              set {
                numFiniteBuckets_ = value;
              }
            }

            /// <summary>Field number for the "width" field.</summary>
            public const int WidthFieldNumber = 2;
            private double width_;
            /// <summary>
            ///  Must be greater than 0.
            /// </summary>
            public double Width {
              get { return width_; }
              set {
                width_ = value;
              }
            }

            /// <summary>Field number for the "offset" field.</summary>
            public const int OffsetFieldNumber = 3;
            private double offset_;
            /// <summary>
            ///  Lower bound of the first bucket.
            /// </summary>
            public double Offset {
              get { return offset_; }
              set {
                offset_ = value;
              }
            }

            public override bool Equals(object other) {
              return Equals(other as Linear);
            }

            public bool Equals(Linear other) {
              if (ReferenceEquals(other, null)) {
                return false;
              }
              if (ReferenceEquals(other, this)) {
                return true;
              }
              if (NumFiniteBuckets != other.NumFiniteBuckets) return false;
              if (Width != other.Width) return false;
              if (Offset != other.Offset) return false;
              return true;
            }

            public override int GetHashCode() {
              int hash = 1;
              if (NumFiniteBuckets != 0) hash ^= NumFiniteBuckets.GetHashCode();
              if (Width != 0D) hash ^= Width.GetHashCode();
              if (Offset != 0D) hash ^= Offset.GetHashCode();
              return hash;
            }

            public override string ToString() {
              return pb::JsonFormatter.ToDiagnosticString(this);
            }

            public void WriteTo(pb::CodedOutputStream output) {
              if (NumFiniteBuckets != 0) {
                output.WriteRawTag(8);
                output.WriteInt32(NumFiniteBuckets);
              }
              if (Width != 0D) {
                output.WriteRawTag(17);
                output.WriteDouble(Width);
              }
              if (Offset != 0D) {
                output.WriteRawTag(25);
                output.WriteDouble(Offset);
              }
            }

            public int CalculateSize() {
              int size = 0;
              if (NumFiniteBuckets != 0) {
                size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumFiniteBuckets);
              }
              if (Width != 0D) {
                size += 1 + 8;
              }
              if (Offset != 0D) {
                size += 1 + 8;
              }
              return size;
            }

            public void MergeFrom(Linear other) {
              if (other == null) {
                return;
              }
              if (other.NumFiniteBuckets != 0) {
                NumFiniteBuckets = other.NumFiniteBuckets;
              }
              if (other.Width != 0D) {
                Width = other.Width;
              }
              if (other.Offset != 0D) {
                Offset = other.Offset;
              }
            }

            public void MergeFrom(pb::CodedInputStream input) {
              uint tag;
              while ((tag = input.ReadTag()) != 0) {
                switch(tag) {
                  default:
                    input.SkipLastField();
                    break;
                  case 8: {
                    NumFiniteBuckets = input.ReadInt32();
                    break;
                  }
                  case 17: {
                    Width = input.ReadDouble();
                    break;
                  }
                  case 25: {
                    Offset = input.ReadDouble();
                    break;
                  }
                }
              }
            }

          }

          /// <summary>
          ///  Specify a sequence of buckets that have a width that is proportional to
          ///  the value of the lower bound.  Each bucket represents a constant relative
          ///  uncertainty on a specific value in the bucket.
          ///
          ///  Defines `num_finite_buckets + 2` (= N) buckets with these boundaries for
          ///  bucket i:
          ///
          ///     Upper bound (0 &lt;= i &lt; N-1):     scale * (growth_factor ^ i).
          ///     Lower bound (1 &lt;= i &lt; N):       scale * (growth_factor ^ (i - 1)).
          /// </summary>
          [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
          public sealed partial class Exponential : pb::IMessage<Exponential> {
            private static readonly pb::MessageParser<Exponential> _parser = new pb::MessageParser<Exponential>(() => new Exponential());
            public static pb::MessageParser<Exponential> Parser { get { return _parser; } }

            public static pbr::MessageDescriptor Descriptor {
              get { return global::Google.Api.Distribution.Types.BucketOptions.Descriptor.NestedTypes[1]; }
            }

            pbr::MessageDescriptor pb::IMessage.Descriptor {
              get { return Descriptor; }
            }

            public Exponential() {
              OnConstruction();
            }

            partial void OnConstruction();

            public Exponential(Exponential other) : this() {
              numFiniteBuckets_ = other.numFiniteBuckets_;
              growthFactor_ = other.growthFactor_;
              scale_ = other.scale_;
            }

            public Exponential Clone() {
              return new Exponential(this);
            }

            /// <summary>Field number for the "num_finite_buckets" field.</summary>
            public const int NumFiniteBucketsFieldNumber = 1;
            private int numFiniteBuckets_;
            /// <summary>
            ///  Must be greater than 0.
            /// </summary>
            public int NumFiniteBuckets {
              get { return numFiniteBuckets_; }
              set {
                numFiniteBuckets_ = value;
              }
            }

            /// <summary>Field number for the "growth_factor" field.</summary>
            public const int GrowthFactorFieldNumber = 2;
            private double growthFactor_;
            /// <summary>
            ///  Must be greater than 1.
            /// </summary>
            public double GrowthFactor {
              get { return growthFactor_; }
              set {
                growthFactor_ = value;
              }
            }

            /// <summary>Field number for the "scale" field.</summary>
            public const int ScaleFieldNumber = 3;
            private double scale_;
            /// <summary>
            ///  Must be greater than 0.
            /// </summary>
            public double Scale {
              get { return scale_; }
              set {
                scale_ = value;
              }
            }

            public override bool Equals(object other) {
              return Equals(other as Exponential);
            }

            public bool Equals(Exponential other) {
              if (ReferenceEquals(other, null)) {
                return false;
              }
              if (ReferenceEquals(other, this)) {
                return true;
              }
              if (NumFiniteBuckets != other.NumFiniteBuckets) return false;
              if (GrowthFactor != other.GrowthFactor) return false;
              if (Scale != other.Scale) return false;
              return true;
            }

            public override int GetHashCode() {
              int hash = 1;
              if (NumFiniteBuckets != 0) hash ^= NumFiniteBuckets.GetHashCode();
              if (GrowthFactor != 0D) hash ^= GrowthFactor.GetHashCode();
              if (Scale != 0D) hash ^= Scale.GetHashCode();
              return hash;
            }

            public override string ToString() {
              return pb::JsonFormatter.ToDiagnosticString(this);
            }

            public void WriteTo(pb::CodedOutputStream output) {
              if (NumFiniteBuckets != 0) {
                output.WriteRawTag(8);
                output.WriteInt32(NumFiniteBuckets);
              }
              if (GrowthFactor != 0D) {
                output.WriteRawTag(17);
                output.WriteDouble(GrowthFactor);
              }
              if (Scale != 0D) {
                output.WriteRawTag(25);
                output.WriteDouble(Scale);
              }
            }

            public int CalculateSize() {
              int size = 0;
              if (NumFiniteBuckets != 0) {
                size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumFiniteBuckets);
              }
              if (GrowthFactor != 0D) {
                size += 1 + 8;
              }
              if (Scale != 0D) {
                size += 1 + 8;
              }
              return size;
            }

            public void MergeFrom(Exponential other) {
              if (other == null) {
                return;
              }
              if (other.NumFiniteBuckets != 0) {
                NumFiniteBuckets = other.NumFiniteBuckets;
              }
              if (other.GrowthFactor != 0D) {
                GrowthFactor = other.GrowthFactor;
              }
              if (other.Scale != 0D) {
                Scale = other.Scale;
              }
            }

            public void MergeFrom(pb::CodedInputStream input) {
              uint tag;
              while ((tag = input.ReadTag()) != 0) {
                switch(tag) {
                  default:
                    input.SkipLastField();
                    break;
                  case 8: {
                    NumFiniteBuckets = input.ReadInt32();
                    break;
                  }
                  case 17: {
                    GrowthFactor = input.ReadDouble();
                    break;
                  }
                  case 25: {
                    Scale = input.ReadDouble();
                    break;
                  }
                }
              }
            }

          }

          /// <summary>
          ///  A set of buckets with arbitrary widths.
          ///
          ///  Defines `size(bounds) + 1` (= N) buckets with these boundaries for
          ///  bucket i:
          ///
          ///     Upper bound (0 &lt;= i &lt; N-1):     bounds[i]
          ///     Lower bound (1 &lt;= i &lt; N);       bounds[i - 1]
          ///
          ///  There must be at least one element in `bounds`.  If `bounds` has only one
          ///  element, there are no finite buckets, and that single element is the
          ///  common boundary of the overflow and underflow buckets.
          /// </summary>
          [global::System.Diagnostics.DebuggerNonUserCodeAttribute()]
          public sealed partial class Explicit : pb::IMessage<Explicit> {
            private static readonly pb::MessageParser<Explicit> _parser = new pb::MessageParser<Explicit>(() => new Explicit());
            public static pb::MessageParser<Explicit> Parser { get { return _parser; } }

            public static pbr::MessageDescriptor Descriptor {
              get { return global::Google.Api.Distribution.Types.BucketOptions.Descriptor.NestedTypes[2]; }
            }

            pbr::MessageDescriptor pb::IMessage.Descriptor {
              get { return Descriptor; }
            }

            public Explicit() {
              OnConstruction();
            }

            partial void OnConstruction();

            public Explicit(Explicit other) : this() {
              bounds_ = other.bounds_.Clone();
            }

            public Explicit Clone() {
              return new Explicit(this);
            }

            /// <summary>Field number for the "bounds" field.</summary>
            public const int BoundsFieldNumber = 1;
            private static readonly pb::FieldCodec<double> _repeated_bounds_codec
                = pb::FieldCodec.ForDouble(10);
            private readonly pbc::RepeatedField<double> bounds_ = new pbc::RepeatedField<double>();
            /// <summary>
            ///  The values must be monotonically increasing.
            /// </summary>
            public pbc::RepeatedField<double> Bounds {
              get { return bounds_; }
            }

            public override bool Equals(object other) {
              return Equals(other as Explicit);
            }

            public bool Equals(Explicit other) {
              if (ReferenceEquals(other, null)) {
                return false;
              }
              if (ReferenceEquals(other, this)) {
                return true;
              }
              if(!bounds_.Equals(other.bounds_)) return false;
              return true;
            }

            public override int GetHashCode() {
              int hash = 1;
              hash ^= bounds_.GetHashCode();
              return hash;
            }

            public override string ToString() {
              return pb::JsonFormatter.ToDiagnosticString(this);
            }

            public void WriteTo(pb::CodedOutputStream output) {
              bounds_.WriteTo(output, _repeated_bounds_codec);
            }

            public int CalculateSize() {
              int size = 0;
              size += bounds_.CalculateSize(_repeated_bounds_codec);
              return size;
            }

            public void MergeFrom(Explicit other) {
              if (other == null) {
                return;
              }
              bounds_.Add(other.bounds_);
            }

            public void MergeFrom(pb::CodedInputStream input) {
              uint tag;
              while ((tag = input.ReadTag()) != 0) {
                switch(tag) {
                  default:
                    input.SkipLastField();
                    break;
                  case 10:
                  case 9: {
                    bounds_.AddEntriesFrom(input, _repeated_bounds_codec);
                    break;
                  }
                }
              }
            }

          }

        }
        #endregion

      }

    }
    #endregion

  }

  #endregion

}

#endregion Designer generated code
